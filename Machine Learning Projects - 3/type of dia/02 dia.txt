ğŸ“Œ Kodun AdÄ±m AdÄ±m AÃ§Ä±klamasÄ±

Bu kodda elmas tÃ¼rlerini tahmin etmek iÃ§in SVM (Support Vector Machine) ve MultiOutputClassifier kullandÄ±k. ğŸ†
Veriyi iÅŸledik, sÄ±nÄ±flandÄ±rma modelimizi eÄŸittik ve performansÄ±nÄ± Ã¶lÃ§tÃ¼k. ğŸš€
Åimdi adÄ±m adÄ±m inceleyelim! ğŸ‘‡

ğŸ“‚ 1. Veriyi YÃ¼kleme ve KeÅŸifsel Analiz

ğŸ“Œ AmaÃ§: CSV dosyasÄ±nÄ± yÃ¼kleyip veri hakkÄ±nda bilgi almak.

df = pd.read_csv("type of the Diamond new.csv")
df.head()  # Ä°lk 5 satÄ±rÄ± gÃ¶sterir
df.info()  # Veri tipi ve eksik deÄŸer bilgisi
df.isna().sum()  # Eksik deÄŸer sayÄ±sÄ±nÄ± kontrol eder
df.shape  # Veri setinin kaÃ§ satÄ±r ve sÃ¼tundan oluÅŸtuÄŸunu gÃ¶sterir
ğŸ§ Ne yapÄ±yoruz?

Veri setini yÃ¼klÃ¼yoruz âœ…
Eksik deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol ediyoruz âœ…
Veri tiplerini ve boyutunu inceliyoruz âœ…

ğŸ“Š 2. Veri GÃ¶rselleÅŸtirme

ğŸ“Œ AmaÃ§: Veri iÃ§indeki iliÅŸkileri gÃ¶rmek.

sns.pairplot(df)  # DeÄŸiÅŸkenler arasÄ±ndaki iliÅŸkileri gÃ¶sterir
sns.heatmap(df.corr(numeric_only=True), annot=True)  # Korelasyon matrisi
ğŸ“Œ Neden?
âœ… pairplot() â†’ DeÄŸiÅŸkenler arasÄ±ndaki doÄŸrusal iliÅŸkileri gÃ¶rselleÅŸtirir.
âœ… heatmap() â†’ DeÄŸiÅŸkenler arasÄ±ndaki korelasyonu gÃ¶sterir (Ã¶rneÄŸin, fiyat ile kalite iliÅŸkisi).

ğŸ“ 3. Veriyi Ã–lÃ§eklendirme

ğŸ“Œ AmaÃ§: Verileri 0 ile 1 arasÄ±na Ã¶lÃ§eklemek, bÃ¶ylece modelin daha iyi Ã¶ÄŸrenmesini saÄŸlamak.

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[['x (Premium)', 'z (Very Good)', 'y (Good)']] = scaler.fit_transform(df[['x (Premium)', 'z (Very Good)', 'y (Good)']])
ğŸ”¹ MinMaxScaler ne yapar?
ğŸ‘‰ TÃ¼m sayÄ±sal deÄŸerleri 0-1 aralÄ±ÄŸÄ±na getirir.
ğŸ‘‰ Modelin daha hÄ±zlÄ± ve stabil Ã¶ÄŸrenmesini saÄŸlar.

ğŸ“Œ 4. BaÄŸÄ±mlÄ± ve BaÄŸÄ±msÄ±z DeÄŸiÅŸkenleri Belirleme
ğŸ“Œ AmaÃ§: Modelin hangi sÃ¼tunlarÄ± kullanacaÄŸÄ±nÄ± belirlemek.

x = pd.get_dummies(df.drop(columns=['x (Premium)', 'z (Very Good)', 'y (Good)']))
y = df[['x (Premium)', 'z (Very Good)', 'y (Good)']]

ğŸ§ Burada ne yaptÄ±k?

âœ… BaÄŸÄ±msÄ±z deÄŸiÅŸkenleri (x) belirledik
âœ… Hedef deÄŸiÅŸkenleri (y) seÃ§tik

ğŸ“Œ get_dummies() ne iÅŸe yarar?
ğŸ‘‰ Kategorik deÄŸiÅŸkenleri sayÄ±sal forma Ã§evirir (One-Hot Encoding).

ğŸ“‚ 5. Veriyi Train-Test Olarak AyÄ±rma ve StandartlaÅŸtÄ±rma

ğŸ“Œ AmaÃ§: Modeli eÄŸitmek iÃ§in bir kÄ±smÄ±nÄ± ayÄ±rmak, kalanÄ±yla test etmek.

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)

scaler = StandardScaler()
scaler_X_train = scaler.fit_transform(X_train)
scaler_X_test = scaler.transform(X_test)

ğŸ¯ Neden Train-Test Split yapÄ±yoruz?

ğŸ‘‰ Modelin yeni verilerle nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek iÃ§in.

ğŸ“Œ StandardScaler() ne yapar?
ğŸ‘‰ Verileri ortalama 0, standart sapma 1 olacak ÅŸekilde Ã¶lÃ§ekler (Ã¶zellikle SVM iÃ§in Ã§ok Ã¶nemli!).

ğŸ¤– 6. SVM Modeli ile SÄ±nÄ±flandÄ±rma

ğŸ“Œ AmaÃ§: ElmaslarÄ±n tÃ¼rÃ¼nÃ¼ tahmin etmek iÃ§in SVM modelini eÄŸitmek.

from sklearn.svm import SVC
svc = SVC()
ğŸ’¡ SVC (Support Vector Classifier) nedir?
ğŸ‘‰ Verileri ayrÄ±ÅŸtÄ±rarak doÄŸru sÄ±nÄ±fa atamaya Ã§alÄ±ÅŸÄ±r.

ğŸ”€ 7. MultiOutputClassifier KullanÄ±mÄ±

ğŸ“Œ AmaÃ§: Tek modelle tÃ¼m hedef deÄŸiÅŸkenleri aynÄ± anda tahmin etmek.

from sklearn.multioutput import MultiOutputClassifier
svc = SVC()
multi_output_model = MultiOutputClassifier(svc, n_jobs=-1)
multi_output_model.fit(scaler_X_train, y_train)
pred = multi_output_model.predict(scaler_X_test)

ğŸ›  Burada ne yaptÄ±k?

âœ… MultiOutputClassifier kullanarak tÃ¼m hedefleri aynÄ± anda tahmin ettik.
âœ… n_jobs=-1 ile tÃ¼m iÅŸlemci Ã§ekirdeklerini kullandÄ±k.

ğŸ“Š 8. Model PerformansÄ±nÄ± DeÄŸerlendirme

ğŸ“Œ AmaÃ§: Modelin doÄŸru tahmin yapÄ±p yapmadÄ±ÄŸÄ±nÄ± kontrol etmek.

from sklearn.metrics import classification_report 

labels = ['x (Premium)', 'z (Very Good)', 'y (Good)']
for i, label in enumerate(labels):
    print(f"{label} iÃ§in sÄ±nÄ±flandÄ±rma raporu:")
    print(classification_report(y_test[label], pred[:, i]))
ğŸ§ Burada ne yaptÄ±k?
âœ… Her hedef deÄŸiÅŸken iÃ§in precision, recall, F1-score deÄŸerlerini hesapladÄ±k.

ğŸ“Š 9. Confusion Matrix GÃ¶rselleÅŸtirme

ğŸ“Œ AmaÃ§: Modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini gÃ¶rselleÅŸtirmek.

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, label in enumerate(labels):
    cm = confusion_matrix(y_test[label], pred[:, i])
    sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", ax=axes[i])
    axes[i].set_title(f"Confusion Matrix - {label}")
    axes[i].set_xlabel("Predicted Label")
    axes[i].set_ylabel("True Label")

plt.tight_layout()
plt.show()
ğŸ“Œ Neden kullanÄ±yoruz?
ğŸ‘‰ Modelin hangi sÄ±nÄ±flarÄ± doÄŸru/yanlÄ±ÅŸ tahmin ettiÄŸini gÃ¶rmek iÃ§in.


ğŸ“ˆ 10. ROC-AUC EÄŸrisi Ã‡izme
ğŸ“Œ AmaÃ§: Modelin sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ±nÄ± gÃ¶rselleÅŸtirmek.

from sklearn.metrics import roc_curve, auc

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
for i, label in enumerate(labels):
    fpr, tpr, _ = roc_curve(y_test[label], pred[:, i])
    roc_auc = auc(fpr, tpr)
    axes[i].plot(fpr, tpr, color='darkorange', lw=2, label=f"AUC = {roc_auc:.2f}")
    axes[i].plot([0, 1], [0, 1], color='navy', linestyle='--')
    axes[i].set_title(f"ROC Curve - {label}")
    axes[i].set_xlabel("False Positive Rate")
    axes[i].set_ylabel("True Positive Rate")
    axes[i].legend(loc="lower right")

plt.tight_layout()
plt.show()

ğŸ“Œ Neden Ã¶nemli?

ğŸ‘‰ AUC deÄŸeri ne kadar yÃ¼ksekse model o kadar iyi tahmin yapÄ±yor.

ğŸ¯ SONUÃ‡
âœ… Veriyi yÃ¼kledik ve temizledik.
âœ… Ã–lÃ§eklendirme ve Train-Test ayÄ±rma yaptÄ±k.
âœ… SVM ile model eÄŸittik ve tahmin yaptÄ±k.
âœ… SonuÃ§larÄ± gÃ¶rselleÅŸtirerek analiz ettik.

ğŸ”¥ Elmas tÃ¼rlerini tahmin eden baÅŸarÄ±lÄ± bir model oluÅŸturduk! ğŸš€












